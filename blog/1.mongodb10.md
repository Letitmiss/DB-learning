
# MongoDB主从复制和副本集

http://www.cnblogs.com/yujon/p/

* 主从复制是一个简单的数据库同步备份的集群技术    
1. 在数据库集群中要明确的知道谁是主服务器,主服务器只有一台.
2. 从服务器要知道自己的数据源也就是对于的主服务是谁.
3. --master用来确定主服务器,--slave 和 –source 来控制从服务器

## 集群搭建

### 实现方式

* 主节点的操作会被记录为oplog,存储在系统数据库local的集合oplog.$main中，这个集合中的每个文档都代表主节点的一个操作（不包括查询）
* 从节点定期从主服务器获取oplog数据，并在本机进行执行
* oplog使用的是固定集合，随着操作的逐渐增加，新的文档会逐渐覆盖旧的文档

### 1主1从

* 主服务器8888端口 mongdb.conf 
```
port = 8888
dbpath = data/8888
logpath = log/8888/mongod.log
fork = true
bind_ip=127.0.0.1
master=true

```
* 从服务器7777端口 mongdbslave.conf 
```
port = 7777
dbpath = data/7777
logpath = log/7777/mongod.log
fork = true
bind_ip=127.0.0.1
source=127.0.0.1:8888
slave=true
```

* 启动服务
```
lfg1000708004:/home/mongodb-3.4.10 # ./bin/mongod -f ./conf/mongdb.conf 
about to fork child process, waiting until server is ready for connections.
forked process: 10694
child process started successfully, parent exiting


lfg1000708004:/home/mongodb-3.4.10 # ./bin/mongod -f ./conf/mongdbslave.conf 
about to fork child process, waiting until server is ready for connections.
forked process: 13591
child process started successfully, parent exiting
```
* shell登陆
```
lfg1000708004:/home/mongodb-3.4.10 # ./bin/mongo 127.0.0.1:8888/test
MongoDB shell version v3.4.10
connecting to: mongodb://127.0.0.1:8888/test
MongoDB server version: 3.4.10
MongoDB Enterprise > show dbs
admin  0.000GB
local  0.000GB
MongoDB Enterprise > use gc
switched to db gc
MongoDB Enterprise > db.persons.insert({_id:"1", name:"name1"})
WriteResult({ "nInserted" : 1 })
MongoDB Enterprise > db.getMongo().setSlaveOk()  # 主库设置SlaveOk()



#从库
lfg1000708004:/home/mongodb-3.4.10 # ./bin/mongo 127.0.0.1:7777/test
MongoDB shell version v3.4.10
connecting to: mongodb://127.0.0.1:7777/test
MongoDB server version: 3.4.10
MongoDB Enterprise > show dbs
2017-12-05T12:52:24.561+0800 E QUERY    [thread1] Error: listDatabases failed:{
	"ok" : 0,
	"errmsg" : "not master and slaveOk=false",
	"code" : 13435,
	"codeName" : "NotMasterNoSlaveOk"
} 
MongoDB Enterprise > db.getMongo().setSlaveOk()  #设置SlaveOK
MongoDB Enterprise > show dbs    # 从服务器自动复制了主服务器的数据库
admin  0.000GB
gc     0.000GB
local  0.000GB
MongoDB Enterprise > use gc             
switched to db gc
MongoDB Enterprise > db.persons.find()
{ "_id" : "1", "name" : "name1" }

MongoDB Enterprise > db.persons.insert({ "_id" : "2", "name" : "name2" })   # 从节点不允许write
WriteResult({ "writeError" : { "code" : 10107, "errmsg" : "not master" } })


# 从节点查询信息
MongoDB Enterprise > use local
switched to db local
MongoDB Enterprise > db.sources.find()
{ "_id" : ObjectId("5a26156a36fb47db5885b474"), "host" : "127.0.0.1:8888", "source" : "main", "syncedTo" : Timestamp(1512450388, 1) }
```

* shell加载从
1. 在启动文件中没有配置source启动项
```
在local中主动添加,挂上从服务器,自动主从复制
MongoDB Enterprise > db.sources.insert({host:"127.0.0.1:8888"})


db.printReplicationInfo(): //查看主节点的信息

db.printSlaveReplicationInfo(): //查看从节点的信息
```


* 其他配置
1. --only  从节点 指定复制某个数据库,默认是复制全部数据库
2. --slavedelay  从节点设置主数据库同步数据的延迟(单位是秒)
3. --fastsync 从节点以主数据库的节点快照为节点启动从数据库
4. --autoresync 从节点如果不同步则从新同步数据库
5. --oplogSize  主节点设置oplog的大小(主节点操作记录存储到local的oplog中)


* 问题
1. 主节点挂了,从节点不能自动切换为主节点,而且从节点是不能插入数据的
2. 设置读写分离,主节点写,从节点读,有可能主节点写的压力过大?
3. 从节点上每个数据库都是对主数据库的全量拷贝,有可能从节点压力过大
4. 从节点设置读的路由策略,需要自动扩展?


## 副本集

1. [有图]

三台服务器的集群,有一台故障时,自动切换
* 参数配置
```
lfg1000708004:/home/mongodb-3.4.10/conf # vi mongdb1.conf 
port = 1111
dbpath = data/1111
logpath = log/1111/mongod.log
fork = true
bind_ip=127.0.0.1
replSet=child/127.0.0.1:2222

lfg1000708004:/home/mongodb-3.4.10/conf # vi mongdb2.conf 
port = 2222
dbpath = data/2222
logpath = log/2222/mongod.log
fork = true
bind_ip=127.0.0.1
replSet=child/127.0.0.1:3333

lfg1000708004:/home/mongodb-3.4.10/conf # vi mongdb3.conf 
port = 3333
dbpath = data/3333
logpath = log/333/mongod.log
fork = true
bind_ip=127.0.0.1
replSet=child/127.0.0.1:1111
```
* 启动数据库
```
lfg1000708009:/home/mongdb/mongodb-3.4.10 # ./bin/mongod -f ./conf/mongod1.conf 
about to fork child process, waiting until server is ready for connections.
forked process: 1254
child process started successfully, parent exiting
lfg1000708009:/home/mongdb/mongodb-3.4.10 # ./bin/mongod -f ./conf/mongod2.conf 
about to fork child process, waiting until server is ready for connections.
forked process: 1313
child process started successfully, parent exiting
lfg1000708009:/home/mongdb/mongodb-3.4.10 # ./bin/mongod -f ./conf/mongod3.conf 
about to fork child process, waiting until server is ready for connections.
forked process: 1359
child process started successfully, parent exiting
```
* 初始化
```
MongoDB Enterprise > db.runCommand({"replSetInitiate":
...    {
...       "_id":'child',
...        "members":[{
...         "_id":1,
... "host":"127.0.0.1:1111"
...     },{
... "_id":2,
... "host":"127.0.0.1:2222"
...     },{
... "_id":3,
... "host":"127.0.0.1:3333"
...     }]
...     }
... })
{ "ok" : 1 }


MongoDB Enterprise child:OTHER> rs.status()
{
	"set" : "child",
	"date" : ISODate("2017-12-05T07:22:29.301Z"),
	"myState" : 1,
	"term" : NumberLong(1),
	"heartbeatIntervalMillis" : NumberLong(2000),
	"optimes" : {
		"lastCommittedOpTime" : {
			"ts" : Timestamp(1512458540, 1),
			"t" : NumberLong(1)
		},
		"appliedOpTime" : {
			"ts" : Timestamp(1512458540, 1),
			"t" : NumberLong(1)
		},
		"durableOpTime" : {
			"ts" : Timestamp(1512458540, 1),
			"t" : NumberLong(1)
		}
	},
	"members" : [
		{
			"_id" : 1,
			"name" : "127.0.0.1:1111",
			"health" : 1,
			"state" : 1,
			"stateStr" : "PRIMARY",
			"uptime" : 336,
			"optime" : {
				"ts" : Timestamp(1512458540, 1),
				"t" : NumberLong(1)
			},
			"optimeDate" : ISODate("2017-12-05T07:22:20Z"),
			"infoMessage" : "could not find member to sync from",
			"electionTime" : Timestamp(1512458519, 1),
			"electionDate" : ISODate("2017-12-05T07:21:59Z"),
			"configVersion" : 1,
			"self" : true
		},
		{
			"_id" : 2,
			"name" : "127.0.0.1:2222",
			"health" : 1,
			"state" : 2,
			"stateStr" : "SECONDARY",
			"uptime" : 40,
			"optime" : {
				"ts" : Timestamp(1512458540, 1),
				"t" : NumberLong(1)
			},
			"optimeDurable" : {
				"ts" : Timestamp(1512458540, 1),
				"t" : NumberLong(1)
			},
			"optimeDate" : ISODate("2017-12-05T07:22:20Z"),
			"optimeDurableDate" : ISODate("2017-12-05T07:22:20Z"),
			"lastHeartbeat" : ISODate("2017-12-05T07:22:29.216Z"),
			"lastHeartbeatRecv" : ISODate("2017-12-05T07:22:28.001Z"),
			"pingMs" : NumberLong(0),
			"syncingTo" : "127.0.0.1:1111",
			"configVersion" : 1
		},
		{
			"_id" : 3,
			"name" : "127.0.0.1:3333",
			"health" : 1,
			"state" : 2,
			"stateStr" : "SECONDARY",
			"uptime" : 40,
			"optime" : {
				"ts" : Timestamp(1512458540, 1),
				"t" : NumberLong(1)
			},
			"optimeDurable" : {
				"ts" : Timestamp(1512458540, 1),
				"t" : NumberLong(1)
			},
			"optimeDate" : ISODate("2017-12-05T07:22:20Z"),
			"optimeDurableDate" : ISODate("2017-12-05T07:22:20Z"),
			"lastHeartbeat" : ISODate("2017-12-05T07:22:29.216Z"),
			"lastHeartbeatRecv" : ISODate("2017-12-05T07:22:28.014Z"),
			"pingMs" : NumberLong(0),
			"syncingTo" : "127.0.0.1:1111",
			"configVersion" : 1
		}
	],
	"ok" : 1
}
MongoDB Enterprise child:PRIMARY> 
```
* 关闭活跃节点,然后自动推选出活跃节点
```
lfg1000708009:/home/mongdb/mongodb-3.4.10 # ./bin/mongo 127.0.0.1:2222   # 2222变为活跃节点
MongoDB shell version v3.4.10
connecting to: 127.0.0.1:2222
MongoDB server version: 3.4.10
MongoDB Enterprise child:PRIMARY> 

#启动1111 节点

lfg1000708009:/home/mongdb/mongodb-3.4.10 # ./bin/mongod -f ./conf/mongod1.conf 
about to fork child process, waiting until server is ready for connections.
forked process: 24787
child process started successfully, parent exiting
lfg1000708009:/home/mongdb/mongodb-3.4.10 # ./bin/mongo 127.0.0.1:1111
MongoDB shell version v3.4.10
connecting to: 127.0.0.1:1111
MongoDB server version: 3.4.10
MongoDB Enterprise child:SECONDARY>     # 变为SECONDAR 备份节点
```

* 节点和初始化高级参数
1. standard 常规节点:参与投票有可能成为活跃节点
2. passive 副本节点:参与投票,但是不能成为活跃节点
3. arbiter 仲裁节点:只是参与投票不复制节点也不能成为活跃节点

4.高级参数
Priority  0到1000之间 ,0代表是副本节点 ,1到1000是常规节点
arbiterOnly : true 仲裁节点
用法
`
members":[{
"_id":1,
"host":"127.0.0.1:1111“,
arbiterOnly : true
}]”
`

